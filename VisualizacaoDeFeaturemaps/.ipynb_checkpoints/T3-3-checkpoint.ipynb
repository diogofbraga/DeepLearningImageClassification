{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = \"tensorflow\"\n",
    "#TensorFlow: Channels last order.\n",
    "#Theano: Channels first order.\n",
    "#CNTK: Channels last order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "#from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio as im\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from keras import models #vamos precisar desta biblioteca para aceder às camadas do modelo\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('tf') \n",
    "K.image_data_format() == 'channels_last'\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar e visualizar os dados e fazer as devidas transformações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHTRAIN='./CINIC-10/train'\n",
    "PATHTEST='./CINIC-10/test'\n",
    "\n",
    "CATEGORIES = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "def show_data(path_set):\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(path_set,category)  # create path\n",
    "        for img in os.listdir(path):  # iterate over each image\n",
    "            img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
    "            plt.imshow(img_array)  # graph it\n",
    "            plt.show()  # display!\n",
    "\n",
    "            break\n",
    "        break\n",
    "    return img_array\n",
    "\n",
    "IMG_SIZE = 32\n",
    "\n",
    "def show_resize_data(img_array):\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    plt.imshow(new_array)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './CINIC-10/train/airplane'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bd0e2c197917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_data_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATHTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-a06e6de262fc>\u001b[0m in \u001b[0;36mshow_data\u001b[0;34m(path_set)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCATEGORIES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# create path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# iterate over each image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# convert to array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# graph it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './CINIC-10/train/airplane'"
     ]
    }
   ],
   "source": [
    "show_data_train = show_data(PATHTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_resize_data(show_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data_test = show_data(PATHTEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_resize_data(show_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_data(path_set):\n",
    "    data = []\n",
    "    for category in CATEGORIES:\n",
    "\n",
    "        path = os.path.join(path_set,category)  # create path \n",
    "        class_num = CATEGORIES.index(category)  # get the classification\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image \n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) )  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHTRAIN='./CINIC-10/train'\n",
    "PATHTESTE='./CINIC-10/test'\n",
    "\n",
    "training_data = create_set_data(PATHTRAIN)\n",
    "test_data = create_set_data(PATHTEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)\n",
    "\n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X_train.append(features)\n",
    "    y_train.append(label)\n",
    "\n",
    "print(X_train[0].reshape(-1, IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(test_data)\n",
    "\n",
    "for sample in test_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for features,label in test_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)\n",
    "\n",
    "print(X_test[0].reshape(-1, IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O formato da imagem fica 32 pixels por 32 pixels com três canais.\n",
    "\n",
    "Construir uma rede CNN mais complexa do que a do TP1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3),input_shape=input_shape,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(model, fich):\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file=fich, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisar a arquitetura do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_model(model, \"model_cinic10_cnn_plus.png\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilar o modelo utilizando adam como otimizador, categorical_crossentropy para função de loss e accuracy como metrica de avaliação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss = 'categorical_crossentropy',optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "#lrate = 0.0001\n",
    "#decay = lrate/no_of_epochs\n",
    "#sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "#model.compile(loss='categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo vai treinar durante 15 epochs mas vamos utilizar ModelCheckpoint para guardar os pesos da melhor epoch. val_accuracy será utilizada como métrica para definir o melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"best_weights_cinic_plus.hdf5\", monitor = 'val_accuracy', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino do modelo, onde se inclui o callback para o checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=15,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gravar o melhor modelo (rede e pesos) para utilizar posteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('cinic10_cnn_simples.h5')\n",
    "model.save('cinic10_cnn_plus.h5')\n",
    "\n",
    "#para utilizar:\n",
    "#model=load_model('cinic10_cnn_simples.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar o comportamento da rede durante o periodo de treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funções para visulização do historial de aprendizagem\n",
    "def print_history_accuracy(history):\n",
    "    #print(history.history.keys())\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def print_history_loss(history):\n",
    "    #print(history.history.keys())\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "print_history_accuracy(history)\n",
    "print_history_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se verificar que depois da epoch 13 o modelo começa a entrar em overfitting, no entanto guardamos os pesos da melhor epoch.\n",
    "\n",
    "Só para confirmação podemos carregar algumas imagens e verificar a correspondente previsão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar imagem, label e correspondente previsão\n",
    "def visualize_previsao(x_test, y_test, img_a_mostrar):\n",
    "    print(\"X_test:\",x_test.shape)\n",
    "    print(\"y_test:\",y_test.shape)\n",
    "    print(\"Imagem:\",x_test[img_a_mostrar].shape)\n",
    "    plt.imshow(x_test[img_a_mostrar,:,:,0], cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"label:\",y_test[img_a_mostrar])\n",
    "    print(\"antes do aumento de mais uma dimensão:\",x_test[img_a_mostrar].shape)\n",
    "    imagem_tensor = np.expand_dims(x_test[img_a_mostrar], axis=0)\n",
    "    print(\"depois do aumento de mais uma dimensão:\",imagem_tensor.shape)\n",
    "    print(\"previsão:\",model.predict(imagem_tensor))\n",
    "    classes = model.predict_classes(imagem_tensor)\n",
    "    print('Classe prevista:',classes)\n",
    "    return imagem_tensor\n",
    "\n",
    "\n",
    "imagem_tensor = visualize_previsao(X_test, y_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previsões estão incorretas, mas existe alguma ligação nos detalhes.\n",
    "\n",
    "Vamos agora visualizar as ativações intermédias.\n",
    "\n",
    "Instanciação de um modelo a partir de um tensor de input e uma lista de tensores de output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos buscar os outputs das primeiras 5 (simples) camadas da rede ou 12 para a plus\n",
    "camadas_outputs = []\n",
    "for layer in model.layers[:12]:\n",
    "    print(layer.output.shape)\n",
    "    camadas_outputs.append(layer.output)\n",
    "\n",
    "# e depois criamos um modelo que retorna estes outputs dado os inputs do modelo\n",
    "activation_model = models.Model(inputs=model.input, outputs=camadas_outputs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado o input de uma imagem, este modelo retorna os valores das camadas de ativação no modelo original.\n",
    "Executar o modelo em modo de previsão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activation_model.predict(imagem_tensor) \n",
    "# Retorna uma lista com dois Numpy arrays: um array por camada de ativação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por exemplo, esta é a ativação da primeira camada convolucional da imagem de input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trata-se de um feature map de 32 × 32 com 32 FeatureMaps. Vamos visualizar o 10º FeatureMap de ativação da ativação da primeira camada do modelo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(first_layer_activation[0, :, :, 9], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para melhor compreensão, vamos visualizar todas as ativações em todas as camadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nomes_camadas = []\n",
    "for camada in model.layers[:12]:\n",
    "    nomes_camadas.append(camada.name) # para puder colocar o nome da cada camada nas visualizações\n",
    "    \n",
    "imagens_por_linha = int(first_layer_activation.shape[3] / 2)\n",
    "\n",
    "for nome_camada, ativacao_camada in zip(nomes_camadas, activations): # o zip permite iterar simultaneamente em 2 listas\n",
    "    n_features = ativacao_camada.shape[-1] # Numero de features no feature map, pois é o que está na ultima dimensão\n",
    "    size = ativacao_camada.shape[1] #O feature map tem shape (1, tamanho, tamanho, numero_features).\n",
    "    n_linhas = -(-n_features // imagens_por_linha) # Empilha os canais de ativação nesta matriz\n",
    "    print(\"nome_camada:\",nome_camada)\n",
    "    print(\"n_features:\",n_features)\n",
    "    print(\"size:\",size)\n",
    "    print(\"n_linhas:\",n_linhas)\n",
    "    display_grid = np.zeros((size * n_linhas, imagens_por_linha * size))\n",
    "    for col in range(n_linhas): # para fazer o display com 15 imagens por linha\n",
    "        for lin in range(imagens_por_linha):\n",
    "            #verificar aqui se a imagem existe\n",
    "            imagem = ativacao_camada[0,:,:,col * imagens_por_linha + lin] #isto pode dar erro de out-of-range\n",
    "            imagem -= imagem.mean() # pos-processamento para melhor visualização\n",
    "            imagem /= imagem.std()\n",
    "            imagem *= 64\n",
    "            imagem += 128\n",
    "            imagem = np.clip(imagem, 0, 255).astype('uint8') #valores <0 ficam 0 e >255 ficam = 255\n",
    "            display_grid[col * size : (col + 1) * size,lin * size : (lin + 1) * size] = imagem\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(nome_camada)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
